{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-06 18:02:40,827\tINFO worker.py:1553 -- Started a local Ray instance.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "    <div style=\"margin-left: 50px;display: flex;flex-direction: row;align-items: center\">\n",
       "        <h3 style=\"color: var(--jp-ui-font-color0)\">Ray</h3>\n",
       "        <svg version=\"1.1\" id=\"ray\" width=\"3em\" viewBox=\"0 0 144.5 144.6\" style=\"margin-left: 3em;margin-right: 3em\">\n",
       "            <g id=\"layer-1\">\n",
       "                <path fill=\"#00a2e9\" class=\"st0\" d=\"M97.3,77.2c-3.8-1.1-6.2,0.9-8.3,5.1c-3.5,6.8-9.9,9.9-17.4,9.6S58,88.1,54.8,81.2c-1.4-3-3-4-6.3-4.1\n",
       "                    c-5.6-0.1-9.9,0.1-13.1,6.4c-3.8,7.6-13.6,10.2-21.8,7.6C5.2,88.4-0.4,80.5,0,71.7c0.1-8.4,5.7-15.8,13.8-18.2\n",
       "                    c8.4-2.6,17.5,0.7,22.3,8c1.3,1.9,1.3,5.2,3.6,5.6c3.9,0.6,8,0.2,12,0.2c1.8,0,1.9-1.6,2.4-2.8c3.5-7.8,9.7-11.8,18-11.9\n",
       "                    c8.2-0.1,14.4,3.9,17.8,11.4c1.3,2.8,2.9,3.6,5.7,3.3c1-0.1,2,0.1,3,0c2.8-0.5,6.4,1.7,8.1-2.7s-2.3-5.5-4.1-7.5\n",
       "                    c-5.1-5.7-10.9-10.8-16.1-16.3C84,38,81.9,37.1,78,38.3C66.7,42,56.2,35.7,53,24.1C50.3,14,57.3,2.8,67.7,0.5\n",
       "                    C78.4-2,89,4.7,91.5,15.3c0.1,0.3,0.1,0.5,0.2,0.8c0.7,3.4,0.7,6.9-0.8,9.8c-1.7,3.2-0.8,5,1.5,7.2c6.7,6.5,13.3,13,19.8,19.7\n",
       "                    c1.8,1.8,3,2.1,5.5,1.2c9.1-3.4,17.9-0.6,23.4,7c4.8,6.9,4.6,16.1-0.4,22.9c-5.4,7.2-14.2,9.9-23.1,6.5c-2.3-0.9-3.5-0.6-5.1,1.1\n",
       "                    c-6.7,6.9-13.6,13.7-20.5,20.4c-1.8,1.8-2.5,3.2-1.4,5.9c3.5,8.7,0.3,18.6-7.7,23.6c-7.9,5-18.2,3.8-24.8-2.9\n",
       "                    c-6.4-6.4-7.4-16.2-2.5-24.3c4.9-7.8,14.5-11,23.1-7.8c3,1.1,4.7,0.5,6.9-1.7C91.7,98.4,98,92.3,104.2,86c1.6-1.6,4.1-2.7,2.6-6.2\n",
       "                    c-1.4-3.3-3.8-2.5-6.2-2.6C99.8,77.2,98.9,77.2,97.3,77.2z M72.1,29.7c5.5,0.1,9.9-4.3,10-9.8c0-0.1,0-0.2,0-0.3\n",
       "                    C81.8,14,77,9.8,71.5,10.2c-5,0.3-9,4.2-9.3,9.2c-0.2,5.5,4,10.1,9.5,10.3C71.8,29.7,72,29.7,72.1,29.7z M72.3,62.3\n",
       "                    c-5.4-0.1-9.9,4.2-10.1,9.7c0,0.2,0,0.3,0,0.5c0.2,5.4,4.5,9.7,9.9,10c5.1,0.1,9.9-4.7,10.1-9.8c0.2-5.5-4-10-9.5-10.3\n",
       "                    C72.6,62.3,72.4,62.3,72.3,62.3z M115,72.5c0.1,5.4,4.5,9.7,9.8,9.9c5.6-0.2,10-4.8,10-10.4c-0.2-5.4-4.6-9.7-10-9.7\n",
       "                    c-5.3-0.1-9.8,4.2-9.9,9.5C115,72.1,115,72.3,115,72.5z M19.5,62.3c-5.4,0.1-9.8,4.4-10,9.8c-0.1,5.1,5.2,10.4,10.2,10.3\n",
       "                    c5.6-0.2,10-4.9,9.8-10.5c-0.1-5.4-4.5-9.7-9.9-9.6C19.6,62.3,19.5,62.3,19.5,62.3z M71.8,134.6c5.9,0.2,10.3-3.9,10.4-9.6\n",
       "                    c0.5-5.5-3.6-10.4-9.1-10.8c-5.5-0.5-10.4,3.6-10.8,9.1c0,0.5,0,0.9,0,1.4c-0.2,5.3,4,9.8,9.3,10\n",
       "                    C71.6,134.6,71.7,134.6,71.8,134.6z\"/>\n",
       "            </g>\n",
       "        </svg>\n",
       "        <table>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left\"><b>Python version:</b></td>\n",
       "                <td style=\"text-align: left\"><b>3.9.16</b></td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left\"><b>Ray version:</b></td>\n",
       "                <td style=\"text-align: left\"><b> 2.3.1</b></td>\n",
       "            </tr>\n",
       "            \n",
       "        </table>\n",
       "    </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "RayContext(dashboard_url='', python_version='3.9.16', ray_version='2.3.1', ray_commit='5f14cee8dfc6d61ec4fd3bc2c440f9944e92b33a', address_info={'node_ip_address': '127.0.0.1', 'raylet_ip_address': '127.0.0.1', 'redis_address': None, 'object_store_address': '/tmp/ray/session_2023-04-06_18-02-39_037034_11770/sockets/plasma_store', 'raylet_socket_name': '/tmp/ray/session_2023-04-06_18-02-39_037034_11770/sockets/raylet', 'webui_url': '', 'session_dir': '/tmp/ray/session_2023-04-06_18-02-39_037034_11770', 'metrics_export_port': 65304, 'gcs_address': '127.0.0.1:64870', 'address': '127.0.0.1:64870', 'dashboard_agent_listen_port': 52365, 'node_id': 'a1c60be1c627c82a66c865aa99be9a190b20b528a68bfeec47bb0d83'})"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pprint\n",
    "import ray\n",
    "\n",
    "ray.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiagent_env import GridWorldEnv\n",
    "# Import a Trainable (one of RLlib's built-in algorithms):\n",
    "# We use the PPO algorithm here b/c its very flexible wrt its supported\n",
    "# action spaces and model types and b/c it learns well almost any problem.\n",
    "from ray.rllib.agents.ppo import PPOTrainer, PPOTF1Policy, PPOTF2Policy, PPOTorchPolicy\n",
    "\n",
    "env = GridWorldEnv()\n",
    "\n",
    "policies = {\n",
    "    \"policy_1\": (PPOTF1Policy, env.observation_space, env.action_space, {}),\n",
    "}\n",
    "\n",
    "policy_mapping_fn = lambda agent_id, episode, worker, **kwargs: \"policy_1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-06 18:02:45,259\tINFO algorithm_config.py:2899 -- Your framework setting is 'tf', meaning you are using static-graph mode. Set framework='tf2' to enable eager execution with tf2.x. You may also then want to set eager_tracing=True in order to reach similar execution speed as with static-graph mode.\n",
      "2023-04-06 18:02:45,286\tINFO algorithm.py:506 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'create_env_on_driver': True,\n",
      " 'env': <class 'multiagent_env.GridWorldEnv'>,\n",
      " 'env_config': {},\n",
      " 'framework': 'tf',\n",
      " 'multiagent': {'policies': {'policy_1': (<class 'ray.rllib.algorithms.ppo.ppo_tf_policy.PPOTF1Policy'>,\n",
      "                                          Dict('common': Dict('ore_positions': MultiDiscrete([100 100 100 100 100])), 'friendly': Dict('factory_position': MultiDiscrete([100]), 'robot_ore': MultiDiscrete([51 51 51]), 'robot_positions': MultiDiscrete([101 101 101])), 'opponent': Dict('factory_position': MultiDiscrete([100]), 'robot_ore': MultiDiscrete([51 51 51]), 'robot_positions': MultiDiscrete([101 101 101]))),\n",
      "                                          MultiDiscrete([10 10 10]),\n",
      "                                          {})},\n",
      "                'policy_mapping_fn': <function <lambda> at 0x3674b2b80>}}\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11809)\u001b[0m Metal device set to: Apple M1 Max\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11809)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11809)\u001b[0m systemMemory: 32.00 GB\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11809)\u001b[0m maxCacheSize: 10.67 GB\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11809)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11808)\u001b[0m Metal device set to: Apple M1 Max\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11808)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11808)\u001b[0m systemMemory: 32.00 GB\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11808)\u001b[0m maxCacheSize: 10.67 GB\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11808)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=11808)\u001b[0m 2023-04-06 18:02:48,744\tWARNING env.py:296 -- Your MultiAgentEnv <GridWorldEnv instance> does not have some or all of the needed base-class attributes! Make sure you call `super().__init__()` from within your MutiAgentEnv's constructor. This will raise an error in the future.\n",
      "2023-04-06 18:02:49,532\tWARNING env.py:296 -- Your MultiAgentEnv <GridWorldEnv instance> does not have some or all of the needed base-class attributes! Make sure you call `super().__init__()` from within your MutiAgentEnv's constructor. This will raise an error in the future.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Max\n",
      "\n",
      "systemMemory: 32.00 GB\n",
      "maxCacheSize: 10.67 GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-06 18:02:50,310\tWARNING util.py:67 -- Install gputil for GPU system monitoring.\n"
     ]
    }
   ],
   "source": [
    "config = {\n",
    "    \"env\": GridWorldEnv,  # \"my_env\" <- if we previously have registered the env with `tune.register_env(\"[name]\", lambda config: [returns env object])`.\n",
    "    \"env_config\": {},\n",
    "    \"framework\": \"tf\",  # If users have chosen to install torch instead of tf.\n",
    "    \"create_env_on_driver\": True,\n",
    "    \"multiagent\": {\n",
    "        \"policies\": policies,\n",
    "        \"policy_mapping_fn\": lambda agent_id, episode, worker, **kwargs: \"policy_1\",\n",
    "    },\n",
    "}\n",
    "pprint.pprint(config)\n",
    "# print()\n",
    "# for agent in env.agents:\n",
    "#     print(f\"{agent} is now mapped to {policy_mapping_fn(agent)}\")\n",
    "\n",
    "rllib_trainer = PPOTrainer(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-06 18:03:06,744\tWARNING deprecation.py:50 -- DeprecationWarning: `_get_slice_indices` has been deprecated. This will raise an error in the future!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration=1: R(\"return\")=272.74125000000004\n",
      "Iteration=2: R(\"return\")=197.41812500000003\n",
      "Iteration=3: R(\"return\")=202.12099999999998\n",
      "Iteration=4: R(\"return\")=202.03750000000008\n",
      "Iteration=5: R(\"return\")=181.29900000000006\n"
     ]
    }
   ],
   "source": [
    "# 4) Run `train()` n times. Repeatedly call `train()` now to see rewards increase.\n",
    "# Move on once you see (agent1 + agent2) episode rewards of 10.0 or more.\n",
    "for _ in range(10):\n",
    "    results = rllib_trainer.train()\n",
    "    print(f\"Iteration={rllib_trainer.iteration}: R(\\\"return\\\")={results['episode_reward_mean']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 3 is out of bounds for axis 0 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m obs \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39mreset()\n\u001b[0;32m----> 2\u001b[0m env\u001b[39m.\u001b[39;49mrecord()\n\u001b[1;32m      4\u001b[0m simulation_time \u001b[39m=\u001b[39m \u001b[39m100\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[39massert\u001b[39;00m simulation_time \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/Documents/NUS_Y3S2/CS4246_Project/Simple_world/multiagent_env.py:175\u001b[0m, in \u001b[0;36mGridWorldEnv.record\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[39m# team_0\u001b[39;00m\n\u001b[1;32m    174\u001b[0m x, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_convert_position_to_xy(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfactory_positions[\u001b[39m'\u001b[39m\u001b[39mteam_0\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m--> 175\u001b[0m frame[x][y] \u001b[39m=\u001b[39m \u001b[39m2\u001b[39m\n\u001b[1;32m    177\u001b[0m \u001b[39mfor\u001b[39;00m pos \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrobot_positions[\u001b[39m'\u001b[39m\u001b[39mteam_0\u001b[39m\u001b[39m'\u001b[39m]:\n\u001b[1;32m    178\u001b[0m     \u001b[39mif\u001b[39;00m pos \u001b[39m==\u001b[39m \u001b[39m100\u001b[39m:\n",
      "\u001b[0;31mIndexError\u001b[0m: index 3 is out of bounds for axis 0 with size 1"
     ]
    }
   ],
   "source": [
    "obs = env.reset()\n",
    "env.record()\n",
    "\n",
    "simulation_time = 100\n",
    "assert simulation_time > 1\n",
    "\n",
    "for _ in range(simulation_time-1):\n",
    "    \n",
    "    random_sample_action = {\n",
    "        'team_0': rllib_trainer.compute_action(obs[\"team_0\"], policy_id=\"policy_1\"),\n",
    "        'team_1': rllib_trainer.compute_action(obs[\"team_1\"], policy_id=\"policy_1\"),\n",
    "    }\n",
    "    new_obs, reward, _, _, _ = env.step(random_sample_action)\n",
    "    env.record()\n",
    "env.render(framerate=2)\n",
    "\n",
    "# with out:\n",
    "#     env = MultiAgentArena()\n",
    "#     obs = env.reset()\n",
    "#     while True:\n",
    "#         a1 = rllib_trainer.compute_action(obs[\"agent1\"], policy_id=\"policy1\")\n",
    "#         a2 = rllib_trainer.compute_action(obs[\"agent2\"], policy_id=\"policy2\")    \n",
    "#         obs, rewards, dones, _ = env.step({\"agent1\": a1, \"agent2\": a2})\n",
    "#         out.clear_output(wait=True)\n",
    "#         time.sleep(0.08)\n",
    "#         env.render()\n",
    "#         if dones[\"agent1\"]:\n",
    "#           break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lux",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
